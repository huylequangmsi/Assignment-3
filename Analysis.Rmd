---
title: "Analysis"
author: "Huy Le Quang"
date: "7/15/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F)
```

## 1.Introduction

Coronavirus (Covid19) brings about a more severe crisis than almost any before. To protect people from the coronavirus, governments worldwide have had to implement safety measures that have a huge impact on personal and economic life. This report, however, does not aim at analyzing the consequences of Covid19, but to give an overview of the changes in the total of cases and infection rates over time (from January 2020 until June 2020). This report will zoom in the situation in some selected countries where coronavirus is more prevalent.

## 2. Dataset

The dataset is taken from John Hopkins University (the JHU CSSE COVID-19 Dataset) which monitors the coronavirus epidemie situation all over the world and collects data on daily basis. The main data for analysis is the "Time_series_covid19_confirmed_global" showing the total of confirmed infected cases per country from 22 Jan 2020 until now. This dataset is then merged with the “UID_ISO_FIPS_LookUp_Table” to add some additional country characteristics variables (e.g. population, longitude, latitude, country code, states...)


## 3. Descriptive analysis

The general approach for analysis in this assignment is to first download the two datasets from GitHub, clean and merge these two datasets on Spark server, and then carry out some descriptive analysis (graphs) and regression analysis.

First of all, we need to load necessary packages in R for data cleaning and analysis. There are three packages that we will need in this exercise: tidyverse, sparklyr and lubridate.

```{r, warning=FALSE}

# Load necessary packages

library(tidyverse)
library(sparklyr)
library(lubridate)

```

After loading the necessary packages, we download the two datasets for Coronavirus from Github and store them in two objects: (1) lookup.table and (2) time.series.

```{r, warning=FALSE}

# Download data

lookup.table.url <- "https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv?raw=true"

lookup.table <- read.csv(url(lookup.table.url))


time.series.url <- "https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv?raw=true"
time.series <- read.csv(url(time.series.url))

```

We proceed with cleaning the time.series data by first deleting unnecessary columns, and reshape the time series data in long format. We also calculate the number of days from the begin of data collection (22 January 2020) until the last date of the dataset.

```{r, warning=FALSE}

# Clean the time series dataset

time.series <- time.series[-c(3, 4)] # delete unnecessary columns

names(time.series)[names(time.series) == 'Country.Region'] <- 'country'
names(time.series)[names(time.series) == 'Province.State'] <- 'state'

time.series.long <- pivot_longer(data = time.series,
                          -c(state, country),
                          names_to = "date") # reshape to long format

# Change to date format

time.series.long$date <- as.Date(gsub("X", "", time.series.long$date), "%m.%d.%y") 

begin.date <- as.Date("2020-01-22")

# Calculate the number of days since the start of data collection

time.series.long <- time.series.long %>% 
    mutate(day_difference = date - begin.date)

# Change variable names in lookup dataset

names(lookup.table)[names(lookup.table) == 'Country_Region'] <- 'country'
names(lookup.table)[names(lookup.table) == 'Province_State'] <- 'state'

```

## Establish Spark server and copy two datasets to this server

To take advantage of the ability for large-scale data processing, we set up Spark server and do further analysis on this server.

First, we create a local Spark server, and then copy both datasets that we cleaned above to this server. Further cleaning tasks are: joining two datasets, and make a smaller version of the dataset which includes only 8 countries, namely: Germany, China,Japan, United Kingdom, US, Brazil, and Mexico. Finally, we create two new variables: (1) log number of confirmed cases, and infection rate per 100,000 people.

```{r, warning=FALSE}

# Connect to local Spark server

sc <- spark_connect(master = "local", 
                    version = "2.3")

# Copy two datasets to Spark server

time.series.long <- copy_to(sc, time.series.long, overwrite = T)
lookup.table <- copy_to(sc, lookup.table, overwrite = T)

# Merge two datasets

data_long <- full_join(time.series.long, lookup.table, by = c("state","country"))

# Rename variables

data_long <- data_long %>% 
    rename(latitude = Lat,
           longitude = Long_,
           population = Population,
           country_code = iso3,
           confirmed_cases = value)

# Make a smaller dataset and generate two new variables

data_final <- data_long %>% 
    filter(country == "Germany"|country == "China"|country == "Japan"|
            country == "United Kingdom"|country == "US"|
            country =="Brazil"|country == "Mexico")%>%
    mutate(log.confirmed_cases = log((confirmed_cases+1)),
           infection_rate = confirmed_cases/population*100000)


```

## Draw graphs

After having a cleaned dataset, we start the analysis

```{r, warning=FALSE}

## Overall change in time of log number of cases

ggplot(aes(x = date, y = log.confirmed_cases),
       data = data_final) +
    stat_summary(fun.y = mean,
                 geom = "line") + 
    theme_bw() +
    facet_wrap(~country) +
    labs(x = "Date", y = "Log number of cases",
         title = "Overall change in time of log number of cases by country",
         caption = "Data: JHU CSSE COVID-19 Dataset")

# Infection rate

ggplot(aes(x = date, y = infection_rate),
       data = data_final) +
    stat_summary(fun.y = mean,
                 geom = "line") +
    facet_wrap(~country) +
    scale_y_continuous(labels = scales::number_format(accuracy = 1)) +
    theme_bw() +
    labs(x = "Date", y = "Infection rate (per 100,000 people)",
         title = "Change in time of infection rate by country",
         caption = "Data: JHU CSSE COVID-19 Dataset. Infection rate per 100,000 people")

```

# Regression model

```{r}

data_final %>% lm(formula = log.confirmed_cases ~ country + population + day_difference) %>% 
summary()

```

